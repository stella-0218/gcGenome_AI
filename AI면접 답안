import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score


1-1. 주어진 원시 데이터의 기본 특성을 파악하고, 모델 학습에 사용하기 앞서 어떠한 전처리 단계가 필요한지 구체적으로 서술하세요.

# 주어진 데이터는  Output 칼럼이 존재하고 1,0 으로 구성되어있으며, 앞의 11개 칼럼의 경우 숫자형데이터로 이루어진 칼럼과
# 범주형 데이터로 이루어진 칼럼이 있다. 


############ 데이터 파일 경로####################
file_path = "C:/Users/sandia/Desktop/AI_input.csv"
data = pd.read_csv(file_path)
data = data.iloc[:,1:]

######################################################
############## 데이터 전처리 ###########################
######################################################


############ 1. 범주형 데이터 처리 ##########################
categorical_columns = ['Religion', 'DietGroup', 'FamilyHistory']
data = pd.get_dummies(data, columns=categorical_columns)

train_data = data.sample(frac=0.8, random_state=42)
test_data = data.drop(train_data.index)
...

############ 2. 결측값 처리: NA 값을 평균으로 대체 #############
numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
train_data[numeric_cols] = train_data[numeric_cols].fillna(train_data[numeric_cols].median())
test_data[numeric_cols] = test_data[numeric_cols].fillna(train_data[numeric_cols].median())


object_cols = train_data.select_dtypes(include=['object']).columns
bool_cols = train_data.select_dtypes(include=['bool']).columns

########## 3.  데이터를 모두 'float' 타입으로 변환합니다. ########
for dtype, cols in zip(['object', 'bool'], [object_cols, bool_cols]):
    for col in cols:
        train_data[col] = train_data[col].astype(float)
        test_data[col] = test_data[col].astype(float)


######################## 4. Tensor 변환 ########################
X_train = torch.tensor(train_data.drop('Outcome', axis=1).values).float()
y_train = torch.tensor(train_data['Outcome'].values).float()
X_test = torch.tensor(test_data.drop('Outcome', axis=1).values).float()
y_test = torch.tensor(test_data['Outcome'].values).float()




# 모델 정의
class NeuralNet(nn.Module):
    def __init__(self, input_dim):
        super(NeuralNet, self).__init__()
        self.layer = nn.Linear(input_dim, 1)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        return self.sigmoid(self.layer(x))

# 학습
model = NeuralNet(X_train.shape[1])
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)

epochs = 1000
for epoch in range(epochs):
    optimizer.zero_grad()
    outputs = model(X_train).squeeze()
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()

# 모델의 예측 및 성능 평가
with torch.no_grad():
    test_outputs = model(X_test).squeeze()
    test_predictions = (test_outputs > 0.5).float()
    accuracy = accuracy_score(y_test, test_predictions)
    precision = precision_score(y_test, test_predictions)
    recall = recall_score(y_test, test_predictions)
    f1 = f1_score(y_test, test_predictions)
    roc_auc = roc_auc_score(y_test, test_outputs)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"ROC AUC: {roc_auc:.4f}")



# 임의의 데이터 파일 경로
input_file_path = "C:/Users/sandia/Desktop/input_data.csv"
input_data = pd.read_csv(input_file_path)
input_data = input_data.iloc[:,1:]

# 범주형 데이터 처리: 원-핫 인코딩
for col in categorical_columns:
    if col in input_data.columns:
        input_data = pd.get_dummies(input_data, columns=[col])

# 주어진 'data'와 동일한 열 구조를 갖도록 'input_data' 조정
for col in data.columns:
    if col not in input_data.columns:
        input_data[col] = 0

input_data = input_data[data.columns[:-1]] # Outcome 열은 제외

# 결측값 처리
input_data[numeric_cols] = input_data[numeric_cols].fillna(input_data[numeric_cols].mean())

# 'object' 타입 열을 실수형으로 변환
object_cols = input_data.select_dtypes(include=['object']).columns
for col in object_cols:
    input_data[col] = input_data[col].astype(float)

# 데이터를 Tensor로 변환
input_tensor = torch.tensor(input_data.values.astype(np.float32))

# 2. 모델 예측
with torch.no_grad():
    model.eval()
    predictions = model(input_tensor).squeeze()
    predicted_classes = (predictions > 0.5).float()

# 결과 출력
print("Predicted probabilities:", predictions.numpy())
print("Predicted classes (0 or 1):", predicted_classes.numpy())
