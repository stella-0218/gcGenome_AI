import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
############ 데이터 파일 경로####################
file_path = "C:/Users/sandia/Desktop/AI_input.csv"
data = pd.read_csv(file_path)
data = data.iloc[:,1:]


#######################################################################################################################
##1-1. 주어진 원시 데이터의 기본 특성을 파악하고, 모델 학습에 사용하기 앞서 어떠한 전처리 단계가 필요한지 구체적으로 서술하세요.

# 주어진 데이터는  Output 칼럼이 존재하고 1,0 으로 구성되어있으며, 앞의 11개 칼럼의 경우 숫자형데이터로 이루어진 칼럼과
# 범주형 데이터로 이루어진 칼럼이 있습니다. 0과 1로 구성된 Output 칼럼이 존재하기 때문에, Binary Classification 모델을 학습하기 전에 
# 범주형 데이터는 숫자형 데이터로 변환하여 입력해야 하며, Float로 입력되어야 합니다. NA를 데이터 전처리 과정에서 처리해야 하는데, 
# NA를 포함하는 row를 제거하는 방법은 샘플의 수가 770개 정도에서 절반정도로 줄어드는 리스크가 있기 때문에 제거하기 보다, 다른 값으로 
# 대치하는 방법을 택합니다. 데이터를 살펴보면 이상치로 볼 수 있는, 전반적 범주에서 벗어난 값들이 있기 때문에, 이상치에 영향을 받지 않는
# 중앙값으로 대체하는 방법을 택합니다. 


######################################################
############## 데이터 전처리 ###########################
######################################################


############ 1. 범주형 데이터 처리 ##########################
categorical_columns = ['Religion', 'DietGroup', 'FamilyHistory']
data = pd.get_dummies(data, columns=categorical_columns)

train_data = data.sample(frac=0.8, random_state=42)
test_data = data.drop(train_data.index)

############ 2. 결측값 처리: NA 값을 중앙값으로 대체 #############
numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
train_data[numeric_cols] = train_data[numeric_cols].fillna(train_data[numeric_cols].median())
test_data[numeric_cols] = test_data[numeric_cols].fillna(train_data[numeric_cols].median())


object_cols = train_data.select_dtypes(include=['object']).columns
bool_cols = train_data.select_dtypes(include=['bool']).columns

########## 3.  데이터를 모두 'float' 타입으로 변환합니다. ########
for dtype, cols in zip(['object', 'bool'], [object_cols, bool_cols]):
    for col in cols:
        train_data[col] = train_data[col].astype(float)
        test_data[col] = test_data[col].astype(float)


######################## 4. Tensor 변환 ########################
X_train = torch.tensor(train_data.drop('Outcome', axis=1).values).float()
y_train = torch.tensor(train_data['Outcome'].values).float()
X_test = torch.tensor(test_data.drop('Outcome', axis=1).values).float()
y_test = torch.tensor(test_data['Outcome'].values).float()
#################################################################################################################





#################################################################################################################
##1-2. 주어진 데이터를 사용하여 Binary classification model을 학습하려고 합니다. 
#1) 모델 학습, 2) 성능평가 3) 모델 해석 (Variable Importance) 전략을 구체적으로 설명하세요. (Deep Learning, Machine
#Learning 등 다양한 알고리즘에 대해 서술하세요)

###1.모델 학습###
#-데이터 전처리: 주어진 데이터를 분석하여 결측값, 이상값을 처리하고, 카테고리 변수의 인코딩, 정규화나 스케일링을 수행합니다.

#-알고리즘 선택: Binary classification을 위해 로지스틱 회귀, 의사결정트리, 랜덤 포레스트, SVM, 그래디언트 부스팅, 딥러닝(신경망) 등 다양한 알고리즘을 고려할 수 있습니다.

#-훈련/테스트 데이터 분리: 데이터를 훈련 세트와 테스트 세트로 분리하여 모델의 일반화 성능을 평가합니다.

###2. 성능 평가###
#-Confusion Matrix: TP, TN, FP, FN 값을 통해 정확도, 재현율, 정밀도 등을 계산합니다.

#-ROC-AUC: 모델의 성능을 평가하는 데 사용되는 면적 값으로, 1에 가까울수록 좋은 모델입니다.

#-크로스 밸리데이션: 데이터의 여러 하위 집합에 대해 모델을 훈련하고 평가하여 모델의 안정성을 확인합니다.

###3. 모델 해석 (Variable Importance)###
#-Feature Importance: 랜덤 포레스트나 그래디언트 부스팅과 같은 트리 기반 모델에서는 피처 중요도를 직접 얻을 수 있습니다.

#-Permutation Importance: 모델의 예측에 각 피처가 얼마나 영향을 주는지 평가하는 방법입니다.

#-SHAP (SHapley Additive exPlanations): 각 피처가 모델의 예측에 미치는 기여도를 설명하는 값입니다.

#-LIME (Local Interpretable Model-agnostic Explanations): 복잡한 모델의 예측을 근사하는 간단한 모델을 만들어 해석을 돕습니다.

#-Deep Learning: 딥러닝 모델의 경우, Layer-wise Relevance Propagation (LRP)나 Saliency Maps 같은 방법을 사용하여 입력 피처의 중요도를 해석할 수 있습니다.
#######################################################################################################################






########################################################################################################################
#1-3. 위에서 설명한 전략대로 모델을 학습하고 결과를 해석하세요.
#################################################################
############### Binary Classification model 학습 ################
#################################################################


############## 데이터 전처리 ####################################
############ 1. 범주형 데이터 처리 ##############################
categorical_columns = ['Religion', 'DietGroup', 'FamilyHistory']
data = pd.get_dummies(data, columns=categorical_columns)

train_data = data.sample(frac=0.8, random_state=42)
test_data = data.drop(train_data.index)
...

############ 2. 결측값 처리: NA 값을 평균으로 대체 ###############
numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
train_data[numeric_cols] = train_data[numeric_cols].fillna(train_data[numeric_cols].median())
test_data[numeric_cols] = test_data[numeric_cols].fillna(train_data[numeric_cols].median())


object_cols = train_data.select_dtypes(include=['object']).columns
bool_cols = train_data.select_dtypes(include=['bool']).columns

########## 3.  데이터를 모두 'float' 타입으로 변환합니다. ########
for dtype, cols in zip(['object', 'bool'], [object_cols, bool_cols]):
    for col in cols:
        train_data[col] = train_data[col].astype(float)
        test_data[col] = test_data[col].astype(float)


######################## 4. Tensor 변환 ########################
X_train = torch.tensor(train_data.drop('Outcome', axis=1).values).float()
y_train = torch.tensor(train_data['Outcome'].values).float()
X_test = torch.tensor(test_data.drop('Outcome', axis=1).values).float()
y_test = torch.tensor(test_data['Outcome'].values).float()



############### Binary Classification model 학습 ################
########################## 1.  모델 정의 #########################
class NeuralNet(nn.Module):
    def __init__(self, input_dim):
        super(NeuralNet, self).__init__()
        self.layer = nn.Linear(input_dim, 1)
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        return self.sigmoid(self.layer(x))

######################### 2.  학습  #############################
########device = 'cuda'로 설정하면 GPU 로 연산하도록 할 수 있지만 부동소수연산이기 때문에################# 
######## 따로 gpu로 연산하도록 하지 않고 cpu로 연산하도록 하였습니다. ###################################
model = NeuralNet(X_train.shape[1])
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)

epochs = 1000000
for epoch in range(epochs):
    optimizer.zero_grad()
    outputs = model(X_train).squeeze()
    loss = criterion(outputs, y_train)
    loss.backward()
    optimizer.step()


################### 3. 모델의 예측 및 성능 평가 ####################
with torch.no_grad():
    test_outputs = model(X_test).squeeze()
    test_predictions = (test_outputs > 0.5).float()
    accuracy = accuracy_score(y_test, test_predictions)
    precision = precision_score(y_test, test_predictions)
    recall = recall_score(y_test, test_predictions)
    f1 = f1_score(y_test, test_predictions)
    roc_auc = roc_auc_score(y_test, test_outputs)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"ROC AUC: {roc_auc:.4f}")

####################################################################
####################################################################
##### 학습한 데이터 중 임의의 row를 model 에 input해서 결과를 확인######
# 임의의 데이터 파일 경로
input_file_path = "C:/Users/sandia/Desktop/input_data.csv"
input_data = pd.read_csv(input_file_path)
input_data = input_data.iloc[:,1:]

# 범주형 데이터 처리: 원-핫 인코딩
for col in categorical_columns:
    if col in input_data.columns:
        input_data = pd.get_dummies(input_data, columns=[col])

# 주어진 'data'와 동일한 열 구조를 갖도록 'input_data' 조정
for col in data.columns:
    if col not in input_data.columns:
        input_data[col] = 0

input_data = input_data[data.columns[:-1]] # Outcome 열은 제외

# 결측값 처리
input_data[numeric_cols] = input_data[numeric_cols].fillna(input_data[numeric_cols].mean())

# 'object' 타입 열을 실수형으로 변환
object_cols = input_data.select_dtypes(include=['object']).columns
for col in object_cols:
    input_data[col] = input_data[col].astype(float)

# 데이터를 Tensor로 변환
input_tensor = torch.tensor(input_data.values.astype(np.float32))

# 2. 모델 예측
with torch.no_grad():
    model.eval()
    predictions = model(input_tensor).squeeze()
    predicted_classes = (predictions > 0.5).float()

# 결과 출력
print("Predicted probabilities:", predictions.numpy())
print("Predicted classes (0 or 1):", predicted_classes.numpy())
################################################################

